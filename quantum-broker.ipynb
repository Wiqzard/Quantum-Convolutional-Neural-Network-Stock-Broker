{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0cb152e28b24c8e8af1e8a689b6bec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cee667b1c37467d94085d572fe48c84",
              "IPY_MODEL_eaac20fb609441e1860877f64afe70c8",
              "IPY_MODEL_5fd28cdaf28440a1b663cc0b5af5ab75"
            ],
            "layout": "IPY_MODEL_43d9e3db0dae4f9ca00ce715d16d2a6b"
          }
        },
        "4cee667b1c37467d94085d572fe48c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9f436cdb134d21809a0d9c402849f1",
            "placeholder": "​",
            "style": "IPY_MODEL_9c06fb8a76124368b909a24aef92adbf",
            "value": "100%"
          }
        },
        "eaac20fb609441e1860877f64afe70c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_627e0dc65ecd4f1a9bad65b6e5561b59",
            "max": 1950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f9f7d152be048e98d52e538a79beea4",
            "value": 1950
          }
        },
        "5fd28cdaf28440a1b663cc0b5af5ab75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b96cccfaf7942c29e70661d7f43301b",
            "placeholder": "​",
            "style": "IPY_MODEL_97fc1b7c56d2475e87bac25d445502b5",
            "value": " 1950/1950 [00:10&lt;00:00, 197.64it/s]"
          }
        },
        "43d9e3db0dae4f9ca00ce715d16d2a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9f436cdb134d21809a0d9c402849f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c06fb8a76124368b909a24aef92adbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "627e0dc65ecd4f1a9bad65b6e5561b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f9f7d152be048e98d52e538a79beea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b96cccfaf7942c29e70661d7f43301b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97fc1b7c56d2475e87bac25d445502b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuxYZj7IPs0G"
      },
      "outputs": [],
      "source": [
        "!pip install pandas-ta\n",
        "!pip install qiskit\n",
        "!pip install yfinance\n",
        "#!pip install TA-Lib\n",
        "!pip install qiskit_machine_learning\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "import qiskit\n",
        "from qiskit import transpile, assemble\n",
        "from qiskit.visualization import *\n",
        "from qiskit.circuit.random import random_circuit\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_ta as ta\n",
        "import itertools\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import torch\n",
        "from torch.utils.data.dataset import Subset\n",
        "from torch import Tensor\n",
        "import math\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit.compiler import transpile"
      ],
      "metadata": {
        "id": "TnMznx1mP8G8"
      },
      "execution_count": 497,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Processing\n",
        "def is_sqrt(n):\n",
        "    if n > 0:\n",
        "        x = 1 << (n.bit_length() + 1 >> 1)\n",
        "        while True:\n",
        "            y = (x + n // x) >> 1\n",
        "            if y >= x:\n",
        "                return x**2 == n\n",
        "            x = y\n",
        "    elif n == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        raise ValueError(\"square root not defined for negative numbers\")\n",
        "\n",
        "class IndicatorDataset(Dataset):\n",
        "  def __init__(self, ticker: str, start_date: str, end_date: str,  device, dataset: pd.DataFrame=None, window_size=11) -> None:  # , training_length:int, forecast_window:int\n",
        "        self.data = dataset\n",
        "        #self.scaler = StandardScaler()\n",
        "        self.transform = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "        self.device = device\n",
        "        self.window_size = window_size\n",
        "        self.ticker = ticker\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.data: pd.DataFrame= self._get_data(self.ticker, self.start_date, self.end_date)# if dataset == None else dataset\n",
        "        self.labels: np.ndarray = self._create_labels()[int(window_size/2+28):-int(window_size/2+28)]\n",
        "  \n",
        "  def _get_data(self, ticker: str, start_date:str, end_date:str):\n",
        "    df = yf.download(ticker, start_date, end_date)\n",
        "    length = list({\"length\": i} for i in range(6,20+1))\n",
        "    indicators = [{\"kind\": \"rsi\"}, {\"kind\" : \"willr\"}, {\"kind\": \"fwma\"}, {\"kind\": \"ema\"}, {\"kind\": \"sma\"}, {\"kind\": \"hma\"}, {\"kind\": \"tema\"}, {\"kind\": \"cci\"},\n",
        "                   {\"kind\": \"cmo\"}, {\"kind\": \"inertia\"}, {\"kind\": \"pgo\"}, {\"kind\": \"roc\"}, {\"kind\": \"cmf\"}, {\"kind\": \"mom\"}, {\"kind\": \"psl\"}]\n",
        "    ta_s = [{**indicator,**length[i]} for indicator, i in itertools.product(indicators, range(len(indicators)))]\n",
        "    window_size=11\n",
        "    MyStrategy = ta.Strategy(name=\"15x15\", ta=ta_s)\n",
        "    df.ta.strategy(MyStrategy) \n",
        "    return df\n",
        "\n",
        "  def _create_labels(self, window_size=11): #df, col_name,\n",
        "    df = self.data\n",
        "    col_name = \"Close\"\n",
        "    row_counter = 0\n",
        "    total_rows = len(df)\n",
        "    labels = np.zeros(total_rows)\n",
        "    labels[:] = np.nan\n",
        "    print(\"Calculating labels\")\n",
        "    pbar = tqdm(total=total_rows)\n",
        "\n",
        "    while row_counter < total_rows:\n",
        "      if row_counter >= self.window_size - 1:\n",
        "          window_begin = row_counter - (self.window_size - 1)\n",
        "          window_end = row_counter\n",
        "          window_middle = int((window_begin + window_end) / 2)\n",
        "          min_ = np.inf\n",
        "          min_index = -1\n",
        "          max_ = -np.inf\n",
        "          max_index = -1\n",
        "          for i in range(window_begin, window_end + 1):\n",
        "              price = df.iloc[i][col_name]\n",
        "              if price < min_:\n",
        "                  min_ = price\n",
        "                  min_index = i\n",
        "              if price > max_:\n",
        "                  max_ = price\n",
        "                  max_index = i\n",
        "\n",
        "          if max_index == window_middle:\n",
        "              labels[window_middle] = 0\n",
        "          elif min_index == window_middle:\n",
        "              labels[window_middle] = 1\n",
        "          else:\n",
        "              labels[window_middle] = 2\n",
        "\n",
        "      row_counter = row_counter + 1\n",
        "      pbar.update(1)\n",
        "    pbar.close()\n",
        "    return labels\n",
        "\n",
        "  def plot_data(self):\n",
        "    plt.figure(figsize=(10,7))\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Price')\n",
        "    plt.plot(self.data['Close'],lw=1, label='Close Price')\n",
        "    #plt.plot(data['Close'],lw=1, label='Close Price')\n",
        "    idx = 6\n",
        "    for column in self.data:\n",
        "      if idx%15 == 6:\n",
        "        plt.plot(self.data[column], lw=1, label=column)\n",
        "      idx += 1\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  def _transform_features(self) -> np.ndarray:\n",
        "    # Scale features:\n",
        "    scaler = self.transform\n",
        "    scaler.fit(self.data.iloc[int(self.window_size/2+9):-int(self.window_size/2), 6:].values)\n",
        "    scaled_features = scaler.transform(self.data.iloc[int(self.window_size/2+28):-int(self.window_size/2+28), 6:].values)\n",
        "    return scaled_features\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "        return len(self.labels)\n",
        "        #return self.data.shape[0]\n",
        "  \n",
        "  def __getitem__(self, idx: int) -> Tensor:\n",
        "    squarable_datapoint = self._transform_features()[idx]\n",
        "    assert is_sqrt(len(squarable_datapoint)) \n",
        "    len_square = int(math.sqrt(len(squarable_datapoint)))\n",
        "    squared_datapoint = squarable_datapoint\n",
        "    squared_datapoint = torch.from_numpy(squarable_datapoint).reshape(len_square, len_square)\n",
        "    label_position = int(self.labels[idx])\n",
        "    label= np.zeros(3)\n",
        "    label[label_position] = 1\n",
        "    label = torch.from_numpy(label)\n",
        "    #label = torch.tensor(self.labels[idx])\n",
        "\n",
        "    return squared_datapoint.unsqueeze(0).float(), label.float()\n"
      ],
      "metadata": {
        "id": "v3g5ak98GD3C"
      },
      "execution_count": 498,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataloader\n",
        "batch_size = 1\n",
        "shuffle = True\n",
        "drop_last = True\n",
        "num_workers = 0\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_test_ratio = 0.8\n",
        "# [FULL_SEQUENCE, NUM_SEQUENCES]\n",
        "# 30PRI 120 AFTER\n",
        "full_dataset = IndicatorDataset(\"GOOGL\", \"2015-01-01\", \"2022-09-30\", device=device)\n",
        "\n",
        "\n",
        "train_size = int(train_test_ratio * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, [train_size, test_size]\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=shuffle,\n",
        "    drop_last=drop_last,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=shuffle,\n",
        "    drop_last=drop_last,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f0cb152e28b24c8e8af1e8a689b6bec8",
            "4cee667b1c37467d94085d572fe48c84",
            "eaac20fb609441e1860877f64afe70c8",
            "5fd28cdaf28440a1b663cc0b5af5ab75",
            "43d9e3db0dae4f9ca00ce715d16d2a6b",
            "1c9f436cdb134d21809a0d9c402849f1",
            "9c06fb8a76124368b909a24aef92adbf",
            "627e0dc65ecd4f1a9bad65b6e5561b59",
            "0f9f7d152be048e98d52e538a79beea4",
            "9b96cccfaf7942c29e70661d7f43301b",
            "97fc1b7c56d2475e87bac25d445502b5"
          ]
        },
        "id": "uCaZCsDmHWig",
        "outputId": "2457c33b-1e39-4d34-88e7-7fc40606856a"
      },
      "execution_count": 539,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Calculating labels\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1950 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0cb152e28b24c8e8af1e8a689b6bec8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title QuantumCircuit \n",
        "class QuantumCircuit1:\n",
        "    \"\"\" \n",
        "    This class provides a simple interface for interaction \n",
        "    with the quantum circuit \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_qubits, backend, shots):\n",
        "        # --- Circuit definition ---\n",
        "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
        "        \n",
        "        all_qubits = [i for i in range(n_qubits)]\n",
        "        self.theta = qiskit.circuit.Parameter('theta')\n",
        "        \n",
        "        self._circuit.h(all_qubits)\n",
        "        self._circuit.barrier()\n",
        "        self._circuit.ry(self.theta, all_qubits)\n",
        "        \n",
        "        self._circuit.measure_all()\n",
        "        # ---------------------------\n",
        "\n",
        "        self.backend = backend\n",
        "        self.shots = shots\n",
        "    \n",
        "    def run(self, thetas):\n",
        "        t_qc = transpile(self._circuit,\n",
        "                         self.backend)\n",
        "        qobj = assemble(t_qc,\n",
        "                        shots=self.shots,\n",
        "                        parameter_binds = [{self.theta: theta} for theta in thetas])\n",
        "        job = self.backend.run(qobj)\n",
        "        result = job.result().get_counts()\n",
        "        \n",
        "        counts = np.array(list(result.values()))\n",
        "        states = np.array(list(result.keys())).astype(float)\n",
        "        \n",
        "        # Compute probabilities for each state\n",
        "        probabilities = counts / self.shots\n",
        "        # Get state expectation\n",
        "        expectation = np.sum(states * probabilities)\n",
        "        \n",
        "        return np.array([expectation])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sYx7ZQN0P_RT"
      },
      "execution_count": 500,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title QCircuit\n",
        "class QuantumVCircuit:\n",
        "    def __init__(self, kernel_size, backend, shots, threshold):    \n",
        "      '''\n",
        "          the quantum circuit class to execute the convolution operation\n",
        "          args:\n",
        "              kernel_size   =   size of (same as classical conv) kernel/ the image dimension patch\n",
        "              backend       =   the quantum computer hardware to use (only simulator is used here)\n",
        "              shots         =   how many times to run the circuit to get a probability distribution\n",
        "              threshold     =   the threshold value (0-255) to assign theta\n",
        "      '''\n",
        "      # the number of qubits needed\n",
        "      self.n_qubits = kernel_size ** 2\n",
        "      # initiate the circuit\n",
        "      self._circuit = qiskit.QuantumCircuit(self.n_qubits)\n",
        "      # parameters\n",
        "      self._params = [Parameter('θ_{}'.format(i)) for i in range(self.n_qubits)]\n",
        "\n",
        "      for i in range(self.n_qubits):\n",
        "          self._circuit.rx(self._params[i], i)\n",
        "      \n",
        "      self._circuit.barrier()\n",
        "      # add unitary random circuit\n",
        "      self._circuit += random_circuit(self.n_qubits, 2)\n",
        "      self._circuit.measure_all()\n",
        "      # initialize\n",
        "      self.backend   = backend\n",
        "      self.shots     = shots\n",
        "      self.threshold = threshold\n",
        "\n",
        "    def run(self, data):\n",
        "      # reshape input data-> [1, kernel_size, kernel_size] -> [1, self.n_qubits]\n",
        "      data = torch.reshape(data, (1, self.n_qubits))\n",
        "      # encoding data to parameters\n",
        "      thetas = []\n",
        "      for dat in data:\n",
        "          theta = []\n",
        "          for val in dat:\n",
        "              if val > self.threshold:\n",
        "                  theta.append(np.pi)\n",
        "              else:\n",
        "                  theta.append(0)\n",
        "          thetas.append(theta)\n",
        "      # for binding parameters\n",
        "      param_dict = dict()\n",
        "      for theta in thetas:\n",
        "          for i in range(self.n_qubits):\n",
        "              param_dict[self._params[i]] = theta[i]\n",
        "      param_binds = [param_dict]\n",
        "\n",
        "      # execute random quantum circuit\n",
        "      result = qiskit.execute(self._circuit, \n",
        "                              self.backend, \n",
        "                              shots = self.shots, \n",
        "                              parameter_binds = param_binds).result().get_counts()\n",
        "          \n",
        "      # decoding the result\n",
        "      counts = 0\n",
        "      for key, val in result.items():\n",
        "          cnt = sum([int(char) for char in key])\n",
        "          counts += cnt * val\n",
        "\n",
        "      # Compute probabilities for each state\n",
        "      probabilities = counts / (self.shots * self.n_qubits)\n",
        "      \n",
        "      return probabilities"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wy4ao2L00w3K"
      },
      "execution_count": 501,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Draw Circuits\n",
        "simulator = qiskit.Aer.get_backend('aer_simulator')\n",
        "\n",
        "circuit = QuantumCircuit1(1, simulator, 100)\n",
        "print('Expected value for rotation pi {}'.format(circuit.run([np.pi])[0]))\n",
        "circuit._circuit.draw()\n",
        "\n",
        "#backend = qiskit.providers.aer.QasmSimulator(method = \"statevector_gpu\")\n",
        "filter_size = 3\n",
        "circ = QuanvolutionCircuit(filter_size, simulator, 100, 127)\n",
        "data = torch.tensor([[0, 200], [100, 255]])\n",
        "\n",
        "#print(data.size())\n",
        "#print(circ.run(data))\n",
        "\n",
        "circ._circuit.draw()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uq8kTnPCP_PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Quantum Dense Layer\n",
        "class HybridFunction(Function):\n",
        "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def forward(ctx, inputs, quantum_circuit, shift):\n",
        "        \"\"\" Forward pass computation \"\"\"\n",
        "        ctx.shift = shift\n",
        "        ctx.quantum_circuit = quantum_circuit\n",
        "\n",
        "        expectation_z = []\n",
        "        for input in inputs:\n",
        "            expectation_z.append(ctx.quantum_circuit.run(input.tolist()))\n",
        "        result = torch.tensor(expectation_z).cuda()\n",
        "        \n",
        "        ctx.save_for_backward(inputs, result)\n",
        "        return result\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\" Backward pass computation \"\"\"\n",
        "        input, expectation_z = ctx.saved_tensors\n",
        "        input_list = np.array(input.tolist())\n",
        "        \n",
        "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
        "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
        "        \n",
        "        gradients = []\n",
        "        for i in range(len(input_list)):\n",
        "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
        "            expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
        "            \n",
        "            gradient = torch.tensor([expectation_right]).cuda() - torch.tensor([expectation_left]).cuda()\n",
        "            gradients.append(gradient)\n",
        "        \n",
        "        # gradients = np.array([gradients]).T\n",
        "        gradients = torch.tensor([gradients]).cuda()\n",
        "        gradients = torch.transpose(gradients, 0, 1)\n",
        "\n",
        "        # return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
        "        return gradients.float() * grad_output.float(), None, None\n",
        "\n",
        "class Hybrid(nn.Module):\n",
        "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
        "    \n",
        "    def __init__(self, backend, shots, shift):\n",
        "        super(Hybrid, self).__init__()\n",
        "        self.quantum_circuit = QuantumCircuit1(1, backend, shots)\n",
        "        self.shift = shift\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "D7zmZ5AFP_NZ"
      },
      "execution_count": 516,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Quantum Convolution Layer\n",
        "\n",
        "#Custom forward/backward pass for Pytorch\n",
        "class QuanvFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, inputs, in_channels, out_channels, kernel_size, quantum_circuits, shift, verbose=True):\n",
        "        \"\"\"\n",
        "           input  shape : (batch_size, feature_size, length, length)\n",
        "           otuput shape : (batch_size, feature_size', length, length')\n",
        "        \"\"\"\n",
        "        ctx.in_channels      = in_channels\n",
        "        ctx.out_channels     = out_channels\n",
        "        ctx.kernel_size      = kernel_size\n",
        "        ctx.quantum_circuits = quantum_circuits\n",
        "        ctx.shift            = shift\n",
        "\n",
        "        # adjust length \n",
        "        _, _, len_x, len_y = inputs.size()\n",
        "        len_x = len_x - kernel_size + 1\n",
        "        len_y = len_y - kernel_size + 1\n",
        "        \n",
        "        # this calculates the conv results for nxn patches\n",
        "        features = []\n",
        "        ## loop over the images\n",
        "        for input in inputs:\n",
        "            feature = []\n",
        "            ## loop over the circuits\n",
        "            for circuit in quantum_circuits:\n",
        "                # save the results\n",
        "                xys = []\n",
        "                for x in range(len_x):\n",
        "                    ys = []\n",
        "                    for y in range(len_y):\n",
        "                        # get the patches\n",
        "                        data = input[0, x:x+kernel_size, y:y+kernel_size]\n",
        "                        # store the results\n",
        "                        res=circuit.run(data)\n",
        "                        ys.append(res)\n",
        "                    xys.append(ys)\n",
        "                feature.append(xys)\n",
        "            features.append(feature)\n",
        "        # construct the tensor\n",
        "        result = torch.tensor(features)\n",
        "\n",
        "        ctx.save_for_backward(inputs, result)\n",
        "        return result\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output): \n",
        "        input, expectation_z = ctx.saved_tensors\n",
        "        input_list = np.array(input.tolist())\n",
        "        \n",
        "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
        "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
        "        \n",
        "        gradients = []\n",
        "        for i in range(len(input_list)):\n",
        "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
        "            expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
        "            \n",
        "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
        "            gradients.append(gradient)\n",
        "        gradients = np.array([gradients]).T\n",
        "        return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
        "\n",
        "\n",
        "#The actual Quantum convolutional layer\n",
        "class Quanv(nn.Module):\n",
        "    def __init__(self, \n",
        "                 in_channels, \n",
        "                 out_channels, \n",
        "                 kernel_size, \n",
        "                 backend=qiskit.providers.aer.QasmSimulator(method = \"statevector_gpu\"), \n",
        "                 shots=100, \n",
        "                 shift=np.pi/2):\n",
        "        \n",
        "        super(Quanv, self).__init__()\n",
        "        \n",
        "        self.quantum_circuits = [QuantumVCircuit(kernel_size=kernel_size, \n",
        "                                          backend=backend, \n",
        "                                          shots=shots, \n",
        "                                          threshold=0.5) for i in range(out_channels)]\n",
        "        self.in_channels  = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size  = kernel_size\n",
        "        self.shift        = shift\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        return QuanvFunction.apply(inputs, \n",
        "                                   self.in_channels, \n",
        "                                   self.out_channels, \n",
        "                                   self.kernel_size,\n",
        "                                   self.quantum_circuits, \n",
        "                                   self.shift)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ghCg_8Qi3FcI"
      },
      "execution_count": 504,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Classical CNN\n",
        "\n",
        "#CNN with Quantum Fully Connected Layer\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.dropout = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(256, 64)\n",
        "        self.fc2 = nn.Linear(64, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x.float().cuda()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TDo8gsT9P_Go"
      },
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CNN with Quantum Dense Layer\n",
        "#CNN with Quantum Fully Connected Layer\n",
        "class NetQF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetQF, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.dropout = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(256, 64)\n",
        "        self.fc2 = nn.Linear(64, 3)\n",
        "        self.hybrid = [Hybrid(qiskit.Aer.get_backend('qasm_simulator'), 100, np.pi / 2) for i in range(3)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = torch.chunk(x, 3, dim=1)\n",
        "        x = tuple([hy(x_) for hy, x_ in zip(self.hybrid, x)])\n",
        "        return torch.cat(x, -1)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PUZ81m_TP_EC"
      },
      "execution_count": 506,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CNN with Quantum C\n",
        "\n",
        "class NetQC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetQC, self).__init__()\n",
        "        self.quanv = Quanv(in_channels=1, out_channels=32, kernel_size=3) \n",
        "        self.conv = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.dropout = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(256, 64)\n",
        "        self.fc2 = nn.Linear(64, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.quanv(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x)"
      ],
      "metadata": {
        "id": "KPSnyRRa3Vy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = NetQF().to(device)\n",
        "summary(model, (1, 15, 15))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INq6xgI_P-4A",
        "outputId": "b9353e8f-2059-470b-bd2e-42beba529949"
      },
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 13, 13]             320\n",
            "            Conv2d-2             [-1, 64, 4, 4]          18,496\n",
            "         Dropout2d-3             [-1, 64, 2, 2]               0\n",
            "            Linear-4                   [-1, 64]          16,448\n",
            "            Linear-5                    [-1, 3]             195\n",
            "================================================================\n",
            "Total params: 35,459\n",
            "Trainable params: 35,459\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.05\n",
            "Params size (MB): 0.14\n",
            "Estimated Total Size (MB): 0.19\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 50\n",
        "loss_list = []\n",
        "#BUY => 1, SELL => 0, HOLD => 2\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    total_loss = []\n",
        "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "      \n",
        "        output = model(data)\n",
        "        loss = loss_func(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss.append(loss.item())\n",
        "    loss_list.append(sum(total_loss)/len(total_loss))\n",
        "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
        "        100. * (epoch + 1) / epochs, loss_list[-1]))\n",
        "    \n",
        "path_to_save_model = \"/content/\"\n",
        "experiment = 1\n",
        "torch.save(model.state_dict(),f\"{path_to_save_model}best_train_experiment{experiment}.pth\")"
      ],
      "metadata": {
        "id": "q8f_WoTDCYyN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot Training\n",
        "plt.plot(loss_list)\n",
        "plt.title('Hybrid NN Training Convergence')\n",
        "plt.xlabel('Training Iterations')\n",
        "plt.ylabel('Neg Log Likelihood Loss')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MrxqC560qBjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluation\n",
        "best_model_path = \"/content/best_train_experiment1.pth\"\n",
        "model = Net().to(device)\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    \n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_dataloader):\n",
        "        data = data.float().cuda()\n",
        "        target = target.float().cuda()\n",
        "\n",
        "        output = model(data).cuda()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        #print(pred)\n",
        " \n",
        "        #rint(target.argmax(dim=1, keepdim=True))\n",
        "        correct += pred.eq(target.argmax(dim=1, keepdim=True)).sum().item()\n",
        "        loss = loss_func(output, target)\n",
        "        total_loss.append(loss.item())\n",
        "        \n",
        "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
        "        sum(total_loss) / len(total_loss),\n",
        "        correct / len(test_dataloader) * 100 / batch_size)\n",
        "        )"
      ],
      "metadata": {
        "id": "ZCwklllMSX9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kReGDuurTQQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, cohen_kappa_score\n",
        "import seaborn as sns\n",
        "\n",
        "best_model_path = \"/content/best_train_experiment1.pth\"\n",
        "model = torch.load(best_model_path)\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "true = []\n",
        "for square, label in test_dataloader:\n",
        "  predictions.append(model(square.float().to(device)).argmax(dim=1, keepdim=True).item())\n",
        "  true.append(label.argmax(dim=1, keepdim=True).item())\n",
        "\n",
        "confusion_matrix(true, predictions)"
      ],
      "metadata": {
        "id": "S49UVDWlTQNI"
      },
      "execution_count": 556,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmiurYzyHJE6",
        "outputId": "b2eba1a3-0a61-4ee2-c44b-86c174fab285"
      },
      "execution_count": 565,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, cohen_kappa_score\n",
        "import sklearn\n",
        "\n",
        "f1_weighted = sklearn.metrics.f1_score(true, predictions, labels=None, \n",
        "         average='weighted', sample_weight=None)\n",
        "print(\"F1 score (weighted)\", f1_weighted)\n",
        "print(\"F1 score (micro)\", sklearn.metrics.f1_score(true, predictions, labels=None, \n",
        "         average='micro', sample_weight=None)) \n",
        "print(\"cohen's Kappa\", sklearn.metrics.cohen_kappa_score(true, predictions))\n",
        "\n",
        "conf_mat = sklearn.metrics.confusion_matrix(true, predictions)\n",
        "print(conf_mat)\n",
        "\n",
        "\n",
        "recall = []\n",
        "for i, row in enumerate(conf_mat):\n",
        "    recall.append(np.round(row[i]/np.sum(row), 2))\n",
        "    print(\"Recall of class {} = {}\".format(i, recall[i]))\n",
        "print(\"Recall avg\", sum(recall)/len(recall))\n",
        "\n"
      ],
      "metadata": {
        "id": "zpfMQk_JTQKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33d7c73-2ae9-4486-eacd-e8c6ca7e7892"
      },
      "execution_count": 576,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score (weighted) 0.8144929172075174\n",
            "F1 score (micro) 0.870026525198939\n",
            "cohen's Kappa -0.006867607783288765\n",
            "[[  0   0  31]\n",
            " [  0   0  16]\n",
            " [  0   2 328]]\n",
            "Recall of class 0 = 0.0\n",
            "Recall of class 1 = 0.0\n",
            "Recall of class 2 = 0.99\n",
            "Recall avg 0.33\n"
          ]
        }
      ]
    }
  ]
}